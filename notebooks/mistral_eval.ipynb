{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations'],\n",
       "        num_rows: 363491\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Open-Orca/SlimOrca-Dedup\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example,add_generation=False):\n",
    "    template = ''\n",
    "    \n",
    "    for message in example['conversations']:\n",
    "        if add_generation and message['from'] == 'gpt':\n",
    "             continue\n",
    "        #Remove 'Answer:' from the start of the message\n",
    "        if message['from'] == 'human':\n",
    "            message['from'] = 'user'\n",
    "        if message['from'] == 'gpt':\n",
    "            message['from'] = 'assistant'\n",
    "        template += '<|im_start|>' + message['from'] + '\\n' + message['value'] + '<|im_end|>' + '\\n'\n",
    "        \n",
    "    \n",
    "    if add_generation:\n",
    "            template+='<|im_start|>assistant'\n",
    "   \n",
    "\n",
    "    return {'text':template}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4f8c4be2664be4be4b2af5b6dbb6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10177 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17caad6fe3e24b618120cfbfadb1df48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 10177\n",
      "test_dataset: 2494\n",
      "eval_dataset: 51\n"
     ]
    }
   ],
   "source": [
    "subset= dataset['train'].train_test_split(test_size=0.965, seed=42)\n",
    "train_eval = subset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "test_eval = train_eval['test'].train_test_split(test_size=0.02, seed=42)\n",
    "import functools\n",
    "train_dataset = train_eval['train'].map(formatting_func,remove_columns=['conversations'])\n",
    "test_dataset = test_eval['train']#.map(functools.partial(formatting_func,add_generation=True),remove_columns=['conversations'])\n",
    "eval_dataset = test_eval['test'].map(formatting_func,remove_columns=['conversations'])\n",
    "\n",
    "print(f'train_dataset: {len(train_dataset)}')\n",
    "print(f'test_dataset: {len(test_dataset)}')\n",
    "print(f'eval_dataset: {len(eval_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '<|im_start|>system\\nYou are an AI assistant. You will be given a task. You must generate a detailed and long answer.<|im_end|>\\n<|im_start|>user\\nQuestion: who abandons religion? If there is no answer, please output \"Insufficient information to provide an answer.\". Movie title: Def by Temptation Context: The story is set in New York and revolves around the relationship between two childhood best friends: \"Joel\", who is raised by his religious grandmother after both of his parents are killed in an automobile accident, and \"K\" who abandons religion, moves to New York and becomes a movie star. Joel (now a minister like his deceased father), becomes somewhat disillusioned with Christianity and decides to take a trip to New York to visit his friend, K. While awaiting Joel\\'s arrival, K (played by Kadeem Hardison) visits the local bar and meets the perfect woman (played by Cynthia Bond)--who in reality is a succubus seeking blood, and vengeance against any and all men foolish enough to be tempted by her. The audience is first given a taste of the demon\\'s powers when shortly before meeting K, she seduces and then kills an employee of the local bar she uses as her hunting ground. Later, during sexual intercourse with a patron of the bar (a closeted homosexual), she transforms into a beast and kills him, horribly. During another seduction (and after having met K) she infects a married man with an incurable, flesh-eating disease before sending him home to his wife who promptly shoots him. Later, when K attempts to introduce her to Joel (played by James Bond III) he is astonished when she pretends to have never met him and spends the entire evening with Joel. It is then that K meets fellow bar patron \"Dougy\" an unsuccessful pickup artist (played by Bill Nunn). The next day when she calls on Joel at K\\'s apartment, K decides to confront her and notices that she casts no reflection in the mirror. A frightened K stands passively by as she and Joel leave on a date. K heads to the bar hoping to find Dougy. After confiding in Dougy the day\\'s events. Dougy reveals himself to be an undercover agent belonging to a special task force investigating a string of strange occurrences, disappearances and murders centered around the bar. Dougy and K pay a visit to a medium--Madame Sonia (played by Melba Moore), who goes into a trance and...<|im_end|>\\n<|im_start|>assistant\\n...reveals the succubus\\' true nature, her intentions, and the danger she poses to Joel and other men who fall victim to her temptations. The medium warns K and Dougy that they must act quickly, as the succubus grows more powerful with each victim she claims.\\n\\nK, feeling guilty for initially succumbing to the succubus\\' charms and endangering Joel, becomes determined to end the demon\\'s reign of terror. K and Dougy embark on a mission to gather knowledge about succubi and ways to defeat them. They consult ancient texts, consult with religious scholars, and delve deep into the occult to uncover the key to vanquishing the succubus.\\n\\nMeanwhile, Joel, unaware of the danger he is in, starts falling for the succubus\\' allure. As their relationship deepens, Joel\\'s faith in Christianity starts to waver. He questions the nature of good and evil and wonders whether the strict moral code of his faith is compatible with his desires.\\n\\nOver time, K and Dougy discover that to defeat the succubus, they must rely on their respective strengths: K\\'s deep-rooted faith in Christianity that he had abandoned, and Dougy\\'s knowledge and experience in dealing with supernatural threats. Armed with newfound wisdom and determination, they form a plan to confront the demonic entity and save Joel from imminent doom.\\n\\nBefore they can execute their plan, the succubus senses that something is amiss and attempts to hasten her plans for Joel. She tries to completely sever his ties to Christianity, pushing him to the brink of abandoning his faith entirely. Joel, although conflicted, begins to realize that something sinister is going on and decides to confront the succubus himself.\\n\\nA climactic battle ensues between the succubus, Joel, K, and Dougy. Joel, now aware of the demon\\'s intention, is forced to make a choice between surrendering to temptation or embracing the power of his faith. K, on the other hand, must come to terms with his abandonment of religion and rediscover the strength it once provided him.\\n\\nUltimately, through an intense struggle, the power of friendship, faith, and redemption prevail. Joel and K manage to overcome the succubus by combining their strengths. The succubus, weakened and unable to sustain her hold over her victims, is banished back to the underworld from which she emerged. The damage she caused is undone, and Joel\\'s faith in Christianity is restored.\\n\\nThe movie \"Def by Temptation\" highlights the importance of faith, friendship, and self-discovery. It serves as a reminder that even when faced with unimaginable evil, one can find the strength needed to prevail, both in themselves and in the support of those around them.\\n\\nIn the context of the movie, K is the one who abandons religion, which leads to the events that unfold throughout the story. This abandonment of faith puts both him and his friend, Joel, at risk from the succubus\\' sinister intentions. Through struggle, danger, and self-reflection, K eventually finds his way back to religion, which plays a pivotal role in defeating the supernatural threat facing them.<|im_end|>\\n'}\n",
      "{'conversations': [{'from': 'system', 'value': 'You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.'}, {'from': 'human', 'value': 'On a scale from 0-5, where 0 is \"not similar\" and 5 is \"very similar\", how similar is the sentence \"Doctors have speculated that the body\\'s own estrogen protects against cell damage and improves blood flow.\" to the sentence \"Their belief was based on speculation that estrogen prevents cell damage and improves blood flow.\"?'}, {'from': 'gpt', 'value': 'To compare the similarity of the two sentences, I will analyze their content and structure step-by-step to come up with a similarity score.\\n\\n1. Analyze the main subject: In both sentences, the main subject is related to \"estrogen\" and its effects on \"cell damage\" and \"blood flow\". This indicates a high level of similarity.\\n\\n2. Examine the actions and beliefs: Both sentences mention \"speculation\" regarding the role of estrogen. In the first sentence, it\\'s \"Doctors have speculated\", and in the second, it\\'s \"Their belief was based on speculation\". These phrases convey a similar idea, although they are worded differently.\\n\\n3. Check the overall structure: The sentence structures are somewhat different, but they convey a similar message. The first sentence places more emphasis on doctors and their speculation, while the second sentence focuses on the belief itself. Nevertheless, the overall meaning is similar.\\n\\n4. Assess the similarity in wording: Some key phrases are identical or very similar in both sentences, such as \"estrogen\", \"cell damage\", and \"improves blood flow\". However, differences exist in how the speculation and beliefs are presented.\\n\\nConsidering these factors, I would rate the similarity between the two sentences as a 4 out of 5. While there are differences in sentence structure and the way speculation is presented, the core message and key phrases are very similar.'}]}\n",
      "{'text': \"<|im_start|>system\\nYou are a helpful assistant, who always provide explanation. Think like you are answering to a five year old.<|im_end|>\\n<|im_start|>user\\nWrite the next sentence.\\n\\nKenneth asked Jason for some tips on growing the perfect mustache, because<|im_end|>\\n<|im_start|>assistant\\nhe saw that Jason's mustache was very nice and fluffy, and he wanted to have one just like that too.<|im_end|>\\n\"}\n"
     ]
    }
   ],
   "source": [
    "#Sanity check   \n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])\n",
    "print(eval_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilakshan/anaconda3/envs/llm/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a22722659b84921945b307d97b46d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={'':0},\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=4096,\n",
    "   \n",
    "    add_eos_token=True)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilakshan/anaconda3/envs/llm/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:213: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel,get_peft_model\n",
    "ckpt = '/home/nilakshan/4-LLM/outputs/Mistral-7B-SlimOrca-PEFT_SFT-2024-02-05-23-40'\n",
    "peft_model = PeftModel.from_pretrained(base_model,ckpt).to('cuda:0')\n",
    "peft_model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "from torch import LongTensor, FloatTensor\n",
    "\n",
    "stop_list = [\"<|im_end|>\" ]\n",
    "stop_token_ids = [tokenizer(x,  return_tensors='pt', add_special_tokens=False)['input_ids'] for x in stop_list]\n",
    "stop_token_ids = [LongTensor(x) for x in stop_token_ids]\n",
    "stop_token_ids = [x.to('cuda:0') for x in stop_token_ids]\n",
    "stop_token_ids\n",
    "\n",
    "from torch import eq\n",
    "\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: LongTensor, scores: FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            # print(f\"Testing {input_ids[0][-len(stop_ids[0])+1:]} against {stop_ids[0][1:]}\")\n",
    "            if eq(input_ids[0][-len(stop_ids[0])+1:], stop_ids[0][1:]).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline:\n",
      "<|im_start|>system\n",
      "You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.<|im_end|>\n",
      "<|im_start|>user\n",
      "On a scale from 0-5, where 0 is \"not similar\" and 5 is \"very similar\", how similar is the sentence \"Doctors have speculated that the body's own estrogen protects against cell damage and improves blood flow.\" to the sentence \"Their belief was based on speculation that estrogen prevents cell damage and improves blood flow.\"?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "In my opinion, these two sentences are very similar, as they both discuss the possible protective effects of estrogen against cell damage and its potential benefits on blood flow. However, there may be some minor differences in wording or phrasing between the two sentences, which could affect their level of similarity. Based on this information, I would rate the similarity of the sentences as 4 out of 5.\n",
      "<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "def predict(model,tokenizer,prompt):\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "    prompt = formatting_func(prompt,add_generation=True)['text']\n",
    "\n",
    "\n",
    "\n",
    "    print(\"*** Pipeline:\")\n",
    "    # print('prompt:',prompt)\n",
    "    # print('-'*30)\n",
    "#     prompt = \"\"\"<|im_start|>system\n",
    "# You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.<|im_end|>\n",
    "# <|im_start|>human\n",
    "# On a scale from 0-5, where 0 is \"not similar\" and 5 is \"very similar\", how similar is the sentence \"Doctors have speculated that the body's own estrogen protects against cell damage and improves blood flow.\" to the sentence \"Their belief was based on speculation that estrogen prevents cell damage and improves blood flow.\"?<|im_end|>\n",
    "# <|im_start|>assistant\"\"\"\n",
    "#     print(prompt)\n",
    "#     print('-'*30)\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        add_special_tokens=1,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        repetition_penalty=1.1\n",
    "    )\n",
    "\n",
    "    print(pipe(prompt,stopping_criteria=stopping_criteria)[0]['generated_text'])\n",
    "\n",
    "predict(peft_model,tokenizer,test_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/nilakshan/anaconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:1635: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['from'] + '\\n' + message['value'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"\n",
    "\n",
    "# tokens = tokenizer.apply_chat_template(test_dataset[0]['conversations'][:2], tokenize=1, add_generation_prompt=1, return_tensors=\"pt\")\n",
    "\n",
    "# out = peft_model.generate(tokens, max_new_tokens=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
